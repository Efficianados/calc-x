{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 10:48:15,683] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import gadgets\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL SPLIT:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 7473\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1319\n",
      "    })\n",
      "})\n",
      "NEW SPLIT:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 7273\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1319\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"gsm8k\", \"main\")\n",
    "print(\"ORIGINAL SPLIT:\")\n",
    "print(ds)\n",
    "seed = 0\n",
    "ds_train = ds[\"train\"]\n",
    "ds_test = ds[\"test\"]\n",
    "ds_train, ds_valid = ds_train.train_test_split(seed=seed, test_size=200).values()\n",
    "ds = datasets.DatasetDict({\"train\": ds_train, \"validation\": ds_valid, \"test\": ds_test})\n",
    "print(\"NEW SPLIT:\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xkadlci2/gadgets/gadgets/markup.py:14: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return bs4.BeautifulSoup(step, features=\"html.parser\")\n",
      "/home/xkadlci2/gadgets/gadgets/markup.py:14: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return bs4.BeautifulSoup(step, features=\"html.parser\")\n",
      "/home/xkadlci2/gadgets/gadgets/markup.py:14: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return bs4.BeautifulSoup(step, features=\"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "calc = gadgets.gadget.Calculator()\n",
    "\n",
    "os.makedirs(\"../data/gsm8k\", exist_ok=True)\n",
    "df = {}\n",
    "for split in [\"train\", \"test\", \"validation\"]:\n",
    "    df[split] = ds[split].to_pandas()\n",
    "    examples = df[split].apply(gadgets.gsm8k.parse, axis=1)\n",
    "    df[split].drop(columns=[\"answer\"], inplace=True)\n",
    "    df[split][\"chain\"] = examples.apply(lambda x: gadgets.markup.to_model_markup(example=x)).apply(str)\n",
    "    df[split][\"result\"] = examples.apply(lambda x: x.result)\n",
    "    df[split][\"result_float\"] = df[split][\"result\"].apply(calc._float_eval)\n",
    "    df[split].to_json(f\"../data/gsm8k/{split}.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'chain', 'result', 'result_float'],\n",
       "        num_rows: 7273\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'chain', 'result', 'result_float'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'chain', 'result', 'result_float'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.DatasetDict({\n",
    "    \"train\": datasets.Dataset.from_pandas(df[\"train\"]),\n",
    "    \"validation\": datasets.Dataset.from_pandas(df[\"validation\"]),\n",
    "    \"test\": datasets.Dataset.from_pandas(df[\"test\"])\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58d6868cc35471686ce1e2642963580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711e38a07cca4e84a71e525adbfcf019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2dfc6f15754c52be55ff7603a060dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f553e0c034a62b2abd4aa972da9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fecf3effff4dfaa06fccbb3eae89d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1a5975d10b4c7580469540349fb51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e947204444d94d2b97f09ed9115a7985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub(\"MU-NLPC/Calc-gsm8k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/gsm8k/train.jsonl\") as f:\n",
    "    content = f.read()\n",
    "with open(\"../data/gsm8k/test.jsonl\") as f:\n",
    "    content += f.read()\n",
    "content.count('\\u2028')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.Series([x for x in content if not x.isascii()]).value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "# TODO many random unicode characters that might not be in the tokenizer's vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[\"tokenized\"] = foo[\"index\"].apply(tokenizer.encode).apply(tokenizer.decode, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gadgets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
